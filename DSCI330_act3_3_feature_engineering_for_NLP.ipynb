{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShoSato-047/DSCI330_module_3/blob/main/DSCI330_act3_3_feature_engineering_for_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVlVa674WHwv",
        "outputId": "2c24e46d-ca28-4287-e7ab-31f30d16ff5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: composable in /usr/local/lib/python3.11/dist-packages (0.5.4)\n",
            "Requirement already satisfied: python-forge<19.0,>=18.6 in /usr/local/lib/python3.11/dist-packages (from composable) (18.6.0)\n",
            "Requirement already satisfied: toolz<0.12.0,>=0.11.1 in /usr/local/lib/python3.11/dist-packages (from composable) (0.11.2)\n"
          ]
        }
      ],
      "source": [
        "%pip install composable"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from composable import pipeable\n",
        "from composable.strict import map, filter"
      ],
      "metadata": {
        "id": "Nrdi05DCWQN7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PipeableObject(object):\n",
        "    def __init__(self, function = lambda x: x, after_method_call = False):\n",
        "        self._function = function\n",
        "        self._after_method_call = after_method_call\n",
        "\n",
        "    def __getattr__(self, name):\n",
        "        return PipeableObject(lambda x: getattr(self._function(x), name), after_method_call = False)\n",
        "\n",
        "    def __call__(self, *args, **kwargs):\n",
        "        if self._after_method_call:\n",
        "            return self._function(*args, **kwargs)\n",
        "        else:\n",
        "            return PipeableObject(lambda x: self._function(x)(*args, **kwargs),\n",
        "                                  after_method_call = True)\n",
        "\n",
        "    def __rrshift__(self, other):\n",
        "        return self._function(other)\n",
        "\n",
        "obj = PipeableObject()"
      ],
      "metadata": {
        "id": "dTnpN3a8bNQe"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PipeableAttribute(object):\n",
        "    def __init__(self, function = lambda x: x):\n",
        "        self.function = function\n",
        "\n",
        "    def __getattr__(self, name):\n",
        "        return pipeable(lambda x: getattr(x, name))\n",
        "\n",
        "    def __rrshift__(self, other):\n",
        "        return self.function(other)\n",
        "\n",
        "    def __call__(self, *args, **kwargs):\n",
        "        return self.function(*args, **kwargs)\n",
        "\n",
        "attr = PipeableAttribute()"
      ],
      "metadata": {
        "id": "hki3nhiwbO1Q"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import functools\n",
        "\n",
        "# fold and reduce are basically the same\n",
        "\n",
        "@pipeable\n",
        "def fold(func, init, seq):\n",
        "    return functools.reduce(func, seq, init)\n",
        "\n",
        "@pipeable\n",
        "def reduce(func, seq):\n",
        "    try:\n",
        "        init, seq = seq[0], seq[1:]\n",
        "    except:\n",
        "        init = next(seq)\n",
        "    return functools.reduce(func, seq, init)"
      ],
      "metadata": {
        "id": "PTa_exSJb3ej"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from toolz import get as tlz_get\n",
        "\n",
        "get = pipeable(tlz_get)"
      ],
      "metadata": {
        "id": "7dLaZMH9kGFq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "el = list(range(10))\n",
        "\n",
        "get(2, el)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpYFhqM7sU0x",
        "outputId": "b8e6d683-2c14-4525-cb68-fa9d1ff0895e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get([1,3], el)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ArjxmYnsdhy",
        "outputId": "4adfb6a1-3839-4f63-ab2e-8b840fd44c10"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(d := {str(i): i for i in range(10)})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pShhxqDOshjc",
        "outputId": "f73ecce5-0645-4176-fc40-9aef108663a8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'0': 0,\n",
              " '1': 1,\n",
              " '2': 2,\n",
              " '3': 3,\n",
              " '4': 4,\n",
              " '5': 5,\n",
              " '6': 6,\n",
              " '7': 7,\n",
              " '8': 8,\n",
              " '9': 9}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get('2',d)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caGdTkTzshhf",
        "outputId": "97b1f5f3-20af-4edd-8b07-86e85f701a94"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d >> get(['2','3'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UaO4lTldsuT0",
        "outputId": "7e6aff91-f671-45b4-c683-8dca3cf35aaf"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Feature Engineering for NLP**\n",
        "\n",
        "In this notebook, we discuss\n",
        "\n",
        "1. What is feature engineering?<br>\n",
        "2. Common NLP methods for feature engineering:<br>\n",
        "    a. Bag of Words,<br>\n",
        "    b. Term Frequency-Inverse Document Frequency (TF-IDF),<br>\n",
        "    c. Word Embeddings (Word2Vec, GloVe)<br>\n",
        "    d. BERT Embeddings<br>\n"
      ],
      "metadata": {
        "id": "LcuqLtYMWY2n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# feature >> target\n",
        "# treatment >> response"
      ],
      "metadata": {
        "id": "OFTGCmwftaph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Basics of Feature Engineering - Motivation**\n",
        "\n",
        "* **Tabular data.** Most machine learning (ML) algorithms require tabular data.<br>\n",
        "* **Feature engineering.** The act of creating columns of predictors (features), often from unstructured data.<br>\n",
        "* **Successful feature engineering.** Creating features that<br>\n",
        "    - Capture the signal, that is are helpful in the learning task, and <br>\n",
        "    - Reduce the noise, that is cut out elements of the data that are not helpful.<br>"
      ],
      "metadata": {
        "id": "MNthBIhCXmZh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Example Task - Text classification.**\n",
        "\n",
        "Text classification is\n",
        "* **Supervised learning.** We need training data with a known target value.\n",
        "* **Classification.** We are trying to predict a label (in contrast to *regression* which predicts a quantity).\n",
        "* **Examples.**<br>\n",
        "    - Predict the author of a text.<br>\n",
        "    - Classify the text by overall sentiment, e.g., *positive* or *negative*.\n",
        "    - Determine the outcome of an intervention.<br>"
      ],
      "metadata": {
        "id": "BTGtkyr5YlrO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Common feature engineering techniques for NLP.**"
      ],
      "metadata": {
        "id": "Lenie2mcZq6c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Technique 1 - Bag of Words\n",
        "\n",
        "Bag of words involves\n",
        "1. Tokenizing the text [e.g., words],\n",
        "2. Building a vocabulary [e.g., unique words], and\n",
        "3. Vectorizing the text [e.g, getting the word count]."
      ],
      "metadata": {
        "id": "9emy0ureZyVM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Small example."
      ],
      "metadata": {
        "id": "ZAwfRNTBaXlB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(documents :=\n",
        " [\"Natural language processing is fun\",\n",
        "  \"Language models are important in NLP\",\n",
        "  \"I enjoy learning about artificial intelligence\",\n",
        "  \"Machine learning and NLP are closely related\",\n",
        "  \"Deep learning is a subset of machine learning\",\n",
        " ]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJbaOOsDWW0-",
        "outputId": "960f298f-9315-4081-cb06-53bc27ef1935"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Natural language processing is fun',\n",
              " 'Language models are important in NLP',\n",
              " 'I enjoy learning about artificial intelligence',\n",
              " 'Machine learning and NLP are closely related',\n",
              " 'Deep learning is a subset of machine learning']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 0 - Preprocess the words and tokenize."
      ],
      "metadata": {
        "id": "RY4ivt5Tdlcm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 1 - Tokenize into words."
      ],
      "metadata": {
        "id": "jdceIGbfa-cC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(words :=\n",
        " documents\n",
        " >> map(obj.lower())\n",
        " >> map(obj.split(' '))\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2utVvhHdpW1",
        "outputId": "560fd8e9-e792-4836-f564-64233c29bcf8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['natural', 'language', 'processing', 'is', 'fun'],\n",
              " ['language', 'models', 'are', 'important', 'in', 'nlp'],\n",
              " ['i', 'enjoy', 'learning', 'about', 'artificial', 'intelligence'],\n",
              " ['machine', 'learning', 'and', 'nlp', 'are', 'closely', 'related'],\n",
              " ['deep', 'learning', 'is', 'a', 'subset', 'of', 'machine', 'learning']]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 2 - Build a vocabulary"
      ],
      "metadata": {
        "id": "SyI-zIiOdwe0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set can only contains unique values\n",
        "init_vocab = set([])\n",
        "update_vocab = lambda voc, doc: voc.union(doc)\n",
        "\n",
        "(vocab :=\n",
        " words\n",
        " >> fold(update_vocab,init_vocab)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TabdwpUaazUf",
        "outputId": "bcb64bba-6981-4610-ea3b-4a6c3574daf6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a',\n",
              " 'about',\n",
              " 'and',\n",
              " 'are',\n",
              " 'artificial',\n",
              " 'closely',\n",
              " 'deep',\n",
              " 'enjoy',\n",
              " 'fun',\n",
              " 'i',\n",
              " 'important',\n",
              " 'in',\n",
              " 'intelligence',\n",
              " 'is',\n",
              " 'language',\n",
              " 'learning',\n",
              " 'machine',\n",
              " 'models',\n",
              " 'natural',\n",
              " 'nlp',\n",
              " 'of',\n",
              " 'processing',\n",
              " 'related',\n",
              " 'subset'}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 3 - Create a vector of word counts *for each document* [Dense representation].\n",
        "\n",
        "The *dense representation* will include a count for the whole vocabulary for each document, including zeros for missing words."
      ],
      "metadata": {
        "id": "giEXlDoOd54X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "init_counts = {w:0 for w in vocab}\n",
        "update_counts = lambda cnts, w: cnts | {w:cnts[w] + 1}\n",
        "\n",
        "(bag_of_words_dense :=\n",
        " words\n",
        " >> map(fold(update_counts, init_counts))\n",
        ")\n",
        "# Why are we using map and fold??\n",
        "# because we want to apply the aggregation (count) for each row."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmnWtsIEblB7",
        "outputId": "ecc02760-6cc3-4e42-fab7-2ea2f5a19ead"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'in': 0,\n",
              "  'intelligence': 0,\n",
              "  'i': 0,\n",
              "  'about': 0,\n",
              "  'natural': 1,\n",
              "  'of': 0,\n",
              "  'artificial': 0,\n",
              "  'models': 0,\n",
              "  'nlp': 0,\n",
              "  'subset': 0,\n",
              "  'learning': 0,\n",
              "  'deep': 0,\n",
              "  'and': 0,\n",
              "  'fun': 1,\n",
              "  'is': 1,\n",
              "  'are': 0,\n",
              "  'processing': 1,\n",
              "  'related': 0,\n",
              "  'closely': 0,\n",
              "  'enjoy': 0,\n",
              "  'machine': 0,\n",
              "  'a': 0,\n",
              "  'important': 0,\n",
              "  'language': 1},\n",
              " {'in': 1,\n",
              "  'intelligence': 0,\n",
              "  'i': 0,\n",
              "  'about': 0,\n",
              "  'natural': 0,\n",
              "  'of': 0,\n",
              "  'artificial': 0,\n",
              "  'models': 1,\n",
              "  'nlp': 1,\n",
              "  'subset': 0,\n",
              "  'learning': 0,\n",
              "  'deep': 0,\n",
              "  'and': 0,\n",
              "  'fun': 0,\n",
              "  'is': 0,\n",
              "  'are': 1,\n",
              "  'processing': 0,\n",
              "  'related': 0,\n",
              "  'closely': 0,\n",
              "  'enjoy': 0,\n",
              "  'machine': 0,\n",
              "  'a': 0,\n",
              "  'important': 1,\n",
              "  'language': 1},\n",
              " {'in': 0,\n",
              "  'intelligence': 1,\n",
              "  'i': 1,\n",
              "  'about': 1,\n",
              "  'natural': 0,\n",
              "  'of': 0,\n",
              "  'artificial': 1,\n",
              "  'models': 0,\n",
              "  'nlp': 0,\n",
              "  'subset': 0,\n",
              "  'learning': 1,\n",
              "  'deep': 0,\n",
              "  'and': 0,\n",
              "  'fun': 0,\n",
              "  'is': 0,\n",
              "  'are': 0,\n",
              "  'processing': 0,\n",
              "  'related': 0,\n",
              "  'closely': 0,\n",
              "  'enjoy': 1,\n",
              "  'machine': 0,\n",
              "  'a': 0,\n",
              "  'important': 0,\n",
              "  'language': 0},\n",
              " {'in': 0,\n",
              "  'intelligence': 0,\n",
              "  'i': 0,\n",
              "  'about': 0,\n",
              "  'natural': 0,\n",
              "  'of': 0,\n",
              "  'artificial': 0,\n",
              "  'models': 0,\n",
              "  'nlp': 1,\n",
              "  'subset': 0,\n",
              "  'learning': 1,\n",
              "  'deep': 0,\n",
              "  'and': 1,\n",
              "  'fun': 0,\n",
              "  'is': 0,\n",
              "  'are': 1,\n",
              "  'processing': 0,\n",
              "  'related': 1,\n",
              "  'closely': 1,\n",
              "  'enjoy': 0,\n",
              "  'machine': 1,\n",
              "  'a': 0,\n",
              "  'important': 0,\n",
              "  'language': 0},\n",
              " {'in': 0,\n",
              "  'intelligence': 0,\n",
              "  'i': 0,\n",
              "  'about': 0,\n",
              "  'natural': 0,\n",
              "  'of': 1,\n",
              "  'artificial': 0,\n",
              "  'models': 0,\n",
              "  'nlp': 0,\n",
              "  'subset': 1,\n",
              "  'learning': 2,\n",
              "  'deep': 1,\n",
              "  'and': 0,\n",
              "  'fun': 0,\n",
              "  'is': 1,\n",
              "  'are': 0,\n",
              "  'processing': 0,\n",
              "  'related': 0,\n",
              "  'closely': 0,\n",
              "  'enjoy': 0,\n",
              "  'machine': 1,\n",
              "  'a': 1,\n",
              "  'important': 0,\n",
              "  'language': 0}]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Review - Understanding the two `fold`s\n",
        "\n",
        "To understand how the folds work, we should investigate how the updates happen at each step."
      ],
      "metadata": {
        "id": "N7Ux4ukAm3z9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Understanding the vocabulary fold."
      ],
      "metadata": {
        "id": "BdwqX_linEL1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "init_vocab = set([]) # empty set\n",
        "update_vocab = lambda voc, doc: voc.union(doc)"
      ],
      "metadata": {
        "id": "vaWaOpDvnIRc"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(up := init_vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "era7CI1lndQf",
        "outputId": "61007983-0cae-4315-9ccd-30a28999928d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "set()"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ws = words[0]\n",
        "\n",
        "(ws, (up := update_vocab(up, ws)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFVl4xGUnKva",
        "outputId": "76ba11ab-efcd-49ac-f46a-8d7543fedf96"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['natural', 'language', 'processing', 'is', 'fun'],\n",
              " {'fun', 'is', 'language', 'natural', 'processing'})"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ws = words[1]\n",
        "\n",
        "(ws, (up := update_vocab(up, ws)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jr5ilwnnudz",
        "outputId": "3487390a-f6c3-439a-bd89-59ae12dbbd63"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['language', 'models', 'are', 'important', 'in', 'nlp'],\n",
              " {'are',\n",
              "  'fun',\n",
              "  'important',\n",
              "  'in',\n",
              "  'is',\n",
              "  'language',\n",
              "  'models',\n",
              "  'natural',\n",
              "  'nlp',\n",
              "  'processing'})"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "up = set([])\n",
        "print(up)\n",
        "for ws in words:\n",
        "    up = update_vocab(up, ws)\n",
        "    print(ws, up)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgtIcqrZnDoh",
        "outputId": "20a01657-0d86-445d-ada5-5aa6273de649"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "set()\n",
            "['natural', 'language', 'processing', 'is', 'fun'] {'fun', 'is', 'natural', 'processing', 'language'}\n",
            "['language', 'models', 'are', 'important', 'in', 'nlp'] {'in', 'natural', 'models', 'nlp', 'fun', 'is', 'are', 'processing', 'important', 'language'}\n",
            "['i', 'enjoy', 'learning', 'about', 'artificial', 'intelligence'] {'important', 'learning', 'in', 'fun', 'intelligence', 'i', 'is', 'natural', 'are', 'about', 'processing', 'enjoy', 'artificial', 'models', 'nlp', 'language'}\n",
            "['machine', 'learning', 'and', 'nlp', 'are', 'closely', 'related'] {'in', 'intelligence', 'i', 'about', 'natural', 'artificial', 'models', 'nlp', 'learning', 'and', 'fun', 'is', 'are', 'processing', 'related', 'closely', 'enjoy', 'machine', 'important', 'language'}\n",
            "['deep', 'learning', 'is', 'a', 'subset', 'of', 'machine', 'learning'] {'in', 'intelligence', 'i', 'about', 'natural', 'of', 'artificial', 'models', 'nlp', 'subset', 'learning', 'deep', 'and', 'fun', 'is', 'are', 'processing', 'related', 'closely', 'enjoy', 'machine', 'a', 'important', 'language'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color=\"red\"> Exercise 3.3.1 </font>\n",
        "\n",
        "**Task.** Use a similar approach to explore the fold for creating the word counts.  Be sure to also investigate how the `dict` merge operator `|` works!"
      ],
      "metadata": {
        "id": "IclzXUEVoaQC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here"
      ],
      "metadata": {
        "id": "MKURcY87osUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "init_vocab = set([]) # empty set\n",
        "update_vocab = lambda voc, doc: voc.union(doc)"
      ],
      "metadata": {
        "id": "ANmoRmKxyLkL"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(acc := init_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJNwENKvzsWg",
        "outputId": "df71545a-18cb-41d6-c0c5-2ef6a821f59c"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'important': 0,\n",
              " 'learning': 0,\n",
              " 'deep': 0,\n",
              " 'fun': 0,\n",
              " 'intelligence': 0,\n",
              " 'natural': 0,\n",
              " 'machine': 0,\n",
              " 'processing': 0,\n",
              " 'related': 0,\n",
              " 'closely': 0,\n",
              " 'subset': 0,\n",
              " 'enjoy': 0,\n",
              " 'artificial': 0,\n",
              " 'models': 0,\n",
              " 'nlp': 0,\n",
              " 'language': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc | {w:acc[w] + 1}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-m0NqdxyxAR",
        "outputId": "a6615e0f-a4c2-43f8-e2d3-6644c3f897e9"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'important': 0,\n",
              " 'learning': 1,\n",
              " 'deep': 0,\n",
              " 'fun': 0,\n",
              " 'intelligence': 0,\n",
              " 'natural': 0,\n",
              " 'machine': 0,\n",
              " 'processing': 0,\n",
              " 'related': 0,\n",
              " 'closely': 0,\n",
              " 'subset': 0,\n",
              " 'enjoy': 0,\n",
              " 'artificial': 0,\n",
              " 'models': 0,\n",
              " 'nlp': 0,\n",
              " 'language': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w = doc[0]\n",
        "\n",
        "print(acc)\n",
        "print(w)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3zQA3gRzucc",
        "outputId": "abd8d7e9-ab35-418b-955b-9dd3b2266528"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'important': 0, 'learning': 0, 'deep': 0, 'fun': 0, 'intelligence': 0, 'natural': 0, 'machine': 0, 'processing': 0, 'related': 0, 'closely': 0, 'subset': 0, 'enjoy': 0, 'artificial': 0, 'models': 0, 'nlp': 0, 'language': 0}\n",
            "deep\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out = []\n",
        "\n",
        "for doc in words:\n",
        "    acc = init_counts\n",
        "    print(doc, acc)\n",
        "    for w in doc:\n",
        "      acc = update_counts(acc, w)\n",
        "      print(w, acc)\n",
        "      print('\\n\\n')\n",
        "    out = out + [acc] # this is the map pattern\n",
        "    print(out)\n",
        "    print('\\n\\n\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctTxwFv80L0j",
        "outputId": "75a0ae08-dcba-457c-ec3f-df9af653f888"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['natural', 'language', 'processing', 'fun'] {'important': 0, 'learning': 0, 'deep': 0, 'fun': 0, 'intelligence': 0, 'natural': 0, 'machine': 0, 'processing': 0, 'related': 0, 'closely': 0, 'subset': 0, 'enjoy': 0, 'artificial': 0, 'models': 0, 'nlp': 0, 'language': 0}\n",
            "natural {'important': 0, 'learning': 0, 'deep': 0, 'fun': 0, 'intelligence': 0, 'natural': 1, 'machine': 0, 'processing': 0, 'related': 0, 'closely': 0, 'subset': 0, 'enjoy': 0, 'artificial': 0, 'models': 0, 'nlp': 0, 'language': 0}\n",
            "\n",
            "\n",
            "\n",
            "language {'important': 0, 'learning': 0, 'deep': 0, 'fun': 0, 'intelligence': 0, 'natural': 1, 'machine': 0, 'processing': 0, 'related': 0, 'closely': 0, 'subset': 0, 'enjoy': 0, 'artificial': 0, 'models': 0, 'nlp': 0, 'language': 1}\n",
            "\n",
            "\n",
            "\n",
            "processing {'important': 0, 'learning': 0, 'deep': 0, 'fun': 0, 'intelligence': 0, 'natural': 1, 'machine': 0, 'processing': 1, 'related': 0, 'closely': 0, 'subset': 0, 'enjoy': 0, 'artificial': 0, 'models': 0, 'nlp': 0, 'language': 1}\n",
            "\n",
            "\n",
            "\n",
            "fun {'important': 0, 'learning': 0, 'deep': 0, 'fun': 1, 'intelligence': 0, 'natural': 1, 'machine': 0, 'processing': 1, 'related': 0, 'closely': 0, 'subset': 0, 'enjoy': 0, 'artificial': 0, 'models': 0, 'nlp': 0, 'language': 1}\n",
            "\n",
            "\n",
            "\n",
            "[{'important': 0, 'learning': 0, 'deep': 0, 'fun': 1, 'intelligence': 0, 'natural': 1, 'machine': 0, 'processing': 1, 'related': 0, 'closely': 0, 'subset': 0, 'enjoy': 0, 'artificial': 0, 'models': 0, 'nlp': 0, 'language': 1}]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "['language', 'models', 'important', 'nlp'] {'important': 0, 'learning': 0, 'deep': 0, 'fun': 0, 'intelligence': 0, 'natural': 0, 'machine': 0, 'processing': 0, 'related': 0, 'closely': 0, 'subset': 0, 'enjoy': 0, 'artificial': 0, 'models': 0, 'nlp': 0, 'language': 0}\n",
            "language {'important': 0, 'learning': 0, 'deep': 0, 'fun': 0, 'intelligence': 0, 'natural': 0, 'machine': 0, 'processing': 0, 'related': 0, 'closely': 0, 'subset': 0, 'enjoy': 0, 'artificial': 0, 'models': 0, 'nlp': 0, 'language': 1}\n",
            "\n",
            "\n",
            "\n",
            "models {'important': 0, 'learning': 0, 'deep': 0, 'fun': 0, 'intelligence': 0, 'natural': 0, 'machine': 0, 'processing': 0, 'related': 0, 'closely': 0, 'subset': 0, 'enjoy': 0, 'artificial': 0, 'models': 1, 'nlp': 0, 'language': 1}\n",
            "\n",
            "\n",
            "\n",
            "important {'important': 1, 'learning': 0, 'deep': 0, 'fun': 0, 'intelligence': 0, 'natural': 0, 'machine': 0, 'processing': 0, 'related': 0, 'closely': 0, 'subset': 0, 'enjoy': 0, 'artificial': 0, 'models': 1, 'nlp': 0, 'language': 1}\n",
            "\n",
            "\n",
            "\n",
            "nlp {'important': 1, 'learning': 0, 'deep': 0, 'fun': 0, 'intelligence': 0, 'natural': 0, 'machine': 0, 'processing': 0, 'related': 0, 'closely': 0, 'subset': 0, 'enjoy': 0, 'artificial': 0, 'models': 1, 'nlp': 1, 'language': 1}\n",
            "\n",
            "\n",
            "\n",
            "[{'important': 0, 'learning': 0, 'deep': 0, 'fun': 1, 'intelligence': 0, 'natural': 1, 'machine': 0, 'processing': 1, 'related': 0, 'closely': 0, 'subset': 0, 'enjoy': 0, 'artificial': 0, 'models': 0, 'nlp': 0, 'language': 1}, {'important': 1, 'learning': 0, 'deep': 0, 'fun': 0, 'intelligence': 0, 'natural': 0, 'machine': 0, 'processing': 0, 'related': 0, 'closely': 0, 'subset': 0, 'enjoy': 0, 'artificial': 0, 'models': 1, 'nlp': 1, 'language': 1}]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "['enjoy', 'learning', 'artificial', 'intelligence'] {'important': 0, 'learning': 0, 'deep': 0, 'fun': 0, 'intelligence': 0, 'natural': 0, 'machine': 0, 'processing': 0, 'related': 0, 'closely': 0, 'subset': 0, 'enjoy': 0, 'artificial': 0, 'models': 0, 'nlp': 0, 'language': 0}\n",
            "enjoy {'important': 0, 'learning': 0, 'deep': 0, 'fun': 0, 'intelligence': 0, 'natural': 0, 'machine': 0, 'processing': 0, 'related': 0, 'closely': 0, 'subset': 0, 'enjoy': 1, 'artificial': 0, 'models': 0, 'nlp': 0, 'language': 0}\n",
            "\n",
            "\n",
            "\n",
            "learning {'important': 0, 'learning': 1, 'deep': 0, 'fun': 0, 'intelligence': 0, 'natural': 0, 'machine': 0, 'processing': 0, 'related': 0, 'closely': 0, 'subset': 0, 'enjoy': 1, 'artificial': 0, 'models': 0, 'nlp': 0, 'language': 0}\n",
            "\n",
            "\n",
            "\n",
            "artificial {'important': 0, 'learning': 1, 'deep': 0, 'fun': 0, 'intelligence': 0, 'natural': 0, 'machine': 0, 'processing': 0, 'related': 0, 'closely': 0, 'subset': 0, 'enjoy': 1, 'artificial': 1, 'models': 0, 'nlp': 0, 'language': 0}\n",
            "\n",
            "\n",
            "\n",
            "intelligence {'important': 0, 'learning': 1, 'deep': 0, 'fun': 0, 'intelligence': 1, 'natural': 0, 'machine': 0, 'processing': 0, 'related': 0, 'closely': 0, 'subset': 0, 'enjoy': 1, 'artificial': 1, 'models': 0, 'nlp': 0, 'language': 0}\n",
            "\n",
            "\n",
            "\n",
            "[{'important': 0, 'learning': 0, 'deep': 0, 'fun': 1, 'intelligence': 0, 'natural': 1, 'machine': 0, 'processing': 1, 'related': 0, 'closely': 0, 'subset': 0, 'enjoy': 0, 'artificial': 0, 'models': 0, 'nlp': 0, 'language': 1}, {'important': 1, 'learning': 0, 'deep': 0, 'fun': 0, 'intelligence': 0, 'natural': 0, 'machine': 0, 'processing': 0, 'related': 0, 'closely': 0, 'subset': 0, 'enjoy': 0, 'artificial': 0, 'models': 1, 'nlp': 1, 'language': 1}, {'important': 0, 'learning': 1, 'deep': 0, 'fun': 0, 'intelligence': 1, 'natural': 0, 'machine': 0, 'processing': 0, 'related': 0, 'closely': 0, 'subset': 0, 'enjoy': 1, 'artificial': 1, 'models': 0, 'nlp': 0, 'language': 0}]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "['machine', 'learning', 'nlp', 'closely', 'related'] {'important': 0, 'learning': 0, 'deep': 0, 'fun': 0, 'intelligence': 0, 'natural': 0, 'machine': 0, 'processing': 0, 'related': 0, 'closely': 0, 'subset': 0, 'enjoy': 0, 'artificial': 0, 'models': 0, 'nlp': 0, 'language': 0}\n",
            "machine {'important': 0, 'learning': 0, 'deep': 0, 'fun': 0, 'intelligence': 0, 'natural': 0, 'machine': 1, 'processing': 0, 'related': 0, 'closely': 0, 'subset': 0, 'enjoy': 0, 'artificial': 0, 'models': 0, 'nlp': 0, 'language': 0}\n",
            "\n",
            "\n",
            "\n",
            "learning {'important': 0, 'learning': 1, 'deep': 0, 'fun': 0, 'intelligence': 0, 'natural': 0, 'machine': 1, 'processing': 0, 'related': 0, 'closely': 0, 'subset': 0, 'enjoy': 0, 'artificial': 0, 'models': 0, 'nlp': 0, 'language': 0}\n",
            "\n",
            "\n",
            "\n",
            "nlp {'important': 0, 'learning': 1, 'deep': 0, 'fun': 0, 'intelligence': 0, 'natural': 0, 'machine': 1, 'processing': 0, 'related': 0, 'closely': 0, 'subset': 0, 'enjoy': 0, 'artificial': 0, 'models': 0, 'nlp': 1, 'language': 0}\n",
            "\n",
            "\n",
            "\n",
            "closely {'important': 0, 'learning': 1, 'deep': 0, 'fun': 0, 'intelligence': 0, 'natural': 0, 'machine': 1, 'processing': 0, 'related': 0, 'closely': 1, 'subset': 0, 'enjoy': 0, 'artificial': 0, 'models': 0, 'nlp': 1, 'language': 0}\n",
            "\n",
            "\n",
            "\n",
            "related {'important': 0, 'learning': 1, 'deep': 0, 'fun': 0, 'intelligence': 0, 'natural': 0, 'machine': 1, 'processing': 0, 'related': 1, 'closely': 1, 'subset': 0, 'enjoy': 0, 'artificial': 0, 'models': 0, 'nlp': 1, 'language': 0}\n",
            "\n",
            "\n",
            "\n",
            "[{'important': 0, 'learning': 0, 'deep': 0, 'fun': 1, 'intelligence': 0, 'natural': 1, 'machine': 0, 'processing': 1, 'related': 0, 'closely': 0, 'subset': 0, 'enjoy': 0, 'artificial': 0, 'models': 0, 'nlp': 0, 'language': 1}, {'important': 1, 'learning': 0, 'deep': 0, 'fun': 0, 'intelligence': 0, 'natural': 0, 'machine': 0, 'processing': 0, 'related': 0, 'closely': 0, 'subset': 0, 'enjoy': 0, 'artificial': 0, 'models': 1, 'nlp': 1, 'language': 1}, {'important': 0, 'learning': 1, 'deep': 0, 'fun': 0, 'intelligence': 1, 'natural': 0, 'machine': 0, 'processing': 0, 'related': 0, 'closely': 0, 'subset': 0, 'enjoy': 1, 'artificial': 1, 'models': 0, 'nlp': 0, 'language': 0}, {'important': 0, 'learning': 1, 'deep': 0, 'fun': 0, 'intelligence': 0, 'natural': 0, 'machine': 1, 'processing': 0, 'related': 1, 'closely': 1, 'subset': 0, 'enjoy': 0, 'artificial': 0, 'models': 0, 'nlp': 1, 'language': 0}]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "['deep', 'learning', 'subset', 'machine', 'learning'] {'important': 0, 'learning': 0, 'deep': 0, 'fun': 0, 'intelligence': 0, 'natural': 0, 'machine': 0, 'processing': 0, 'related': 0, 'closely': 0, 'subset': 0, 'enjoy': 0, 'artificial': 0, 'models': 0, 'nlp': 0, 'language': 0}\n",
            "deep {'important': 0, 'learning': 0, 'deep': 1, 'fun': 0, 'intelligence': 0, 'natural': 0, 'machine': 0, 'processing': 0, 'related': 0, 'closely': 0, 'subset': 0, 'enjoy': 0, 'artificial': 0, 'models': 0, 'nlp': 0, 'language': 0}\n",
            "\n",
            "\n",
            "\n",
            "learning {'important': 0, 'learning': 1, 'deep': 1, 'fun': 0, 'intelligence': 0, 'natural': 0, 'machine': 0, 'processing': 0, 'related': 0, 'closely': 0, 'subset': 0, 'enjoy': 0, 'artificial': 0, 'models': 0, 'nlp': 0, 'language': 0}\n",
            "\n",
            "\n",
            "\n",
            "subset {'important': 0, 'learning': 1, 'deep': 1, 'fun': 0, 'intelligence': 0, 'natural': 0, 'machine': 0, 'processing': 0, 'related': 0, 'closely': 0, 'subset': 1, 'enjoy': 0, 'artificial': 0, 'models': 0, 'nlp': 0, 'language': 0}\n",
            "\n",
            "\n",
            "\n",
            "machine {'important': 0, 'learning': 1, 'deep': 1, 'fun': 0, 'intelligence': 0, 'natural': 0, 'machine': 1, 'processing': 0, 'related': 0, 'closely': 0, 'subset': 1, 'enjoy': 0, 'artificial': 0, 'models': 0, 'nlp': 0, 'language': 0}\n",
            "\n",
            "\n",
            "\n",
            "learning {'important': 0, 'learning': 2, 'deep': 1, 'fun': 0, 'intelligence': 0, 'natural': 0, 'machine': 1, 'processing': 0, 'related': 0, 'closely': 0, 'subset': 1, 'enjoy': 0, 'artificial': 0, 'models': 0, 'nlp': 0, 'language': 0}\n",
            "\n",
            "\n",
            "\n",
            "[{'important': 0, 'learning': 0, 'deep': 0, 'fun': 1, 'intelligence': 0, 'natural': 1, 'machine': 0, 'processing': 1, 'related': 0, 'closely': 0, 'subset': 0, 'enjoy': 0, 'artificial': 0, 'models': 0, 'nlp': 0, 'language': 1}, {'important': 1, 'learning': 0, 'deep': 0, 'fun': 0, 'intelligence': 0, 'natural': 0, 'machine': 0, 'processing': 0, 'related': 0, 'closely': 0, 'subset': 0, 'enjoy': 0, 'artificial': 0, 'models': 1, 'nlp': 1, 'language': 1}, {'important': 0, 'learning': 1, 'deep': 0, 'fun': 0, 'intelligence': 1, 'natural': 0, 'machine': 0, 'processing': 0, 'related': 0, 'closely': 0, 'subset': 0, 'enjoy': 1, 'artificial': 1, 'models': 0, 'nlp': 0, 'language': 0}, {'important': 0, 'learning': 1, 'deep': 0, 'fun': 0, 'intelligence': 0, 'natural': 0, 'machine': 1, 'processing': 0, 'related': 1, 'closely': 1, 'subset': 0, 'enjoy': 0, 'artificial': 0, 'models': 0, 'nlp': 1, 'language': 0}, {'important': 0, 'learning': 2, 'deep': 1, 'fun': 0, 'intelligence': 0, 'natural': 0, 'machine': 1, 'processing': 0, 'related': 0, 'closely': 0, 'subset': 1, 'enjoy': 0, 'artificial': 0, 'models': 0, 'nlp': 0, 'language': 0}]\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 3b - Creating a feature vector for each word in the vocabulary."
      ],
      "metadata": {
        "id": "W_4EAA-Djkkd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(features :=\n",
        "{w: [get(w, word_counts)\n",
        " for word_counts in bag_of_words_dense] # words counts for each words\n",
        " for w in vocab\n",
        "}\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KosvCBGYpOex",
        "outputId": "6a506232-f267-448f-d742-b13b4439f2f9"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'in': [0, 1, 0, 0, 0],\n",
              " 'intelligence': [0, 0, 1, 0, 0],\n",
              " 'i': [0, 0, 1, 0, 0],\n",
              " 'about': [0, 0, 1, 0, 0],\n",
              " 'natural': [1, 0, 0, 0, 0],\n",
              " 'of': [0, 0, 0, 0, 1],\n",
              " 'artificial': [0, 0, 1, 0, 0],\n",
              " 'models': [0, 1, 0, 0, 0],\n",
              " 'nlp': [0, 1, 0, 1, 0],\n",
              " 'subset': [0, 0, 0, 0, 1],\n",
              " 'learning': [0, 0, 1, 1, 2],\n",
              " 'deep': [0, 0, 0, 0, 1],\n",
              " 'and': [0, 0, 0, 1, 0],\n",
              " 'fun': [1, 0, 0, 0, 0],\n",
              " 'is': [1, 0, 0, 0, 1],\n",
              " 'are': [0, 1, 0, 1, 0],\n",
              " 'processing': [1, 0, 0, 0, 0],\n",
              " 'related': [0, 0, 0, 1, 0],\n",
              " 'closely': [0, 0, 0, 1, 0],\n",
              " 'enjoy': [0, 0, 1, 0, 0],\n",
              " 'machine': [0, 0, 0, 1, 1],\n",
              " 'a': [0, 0, 0, 0, 1],\n",
              " 'important': [0, 1, 0, 0, 0],\n",
              " 'language': [1, 1, 0, 0, 0]}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import polars as pl\n",
        "\n",
        "pl.DataFrame(features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "0DWFhh49pySh",
        "outputId": "67edc107-9f3c-4f09-b964-b9385b334b9d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "shape: (5, 24)\n",
              "┌─────┬──────────────┬─────┬───────┬───┬─────────┬─────┬───────────┬──────────┐\n",
              "│ in  ┆ intelligence ┆ i   ┆ about ┆ … ┆ machine ┆ a   ┆ important ┆ language │\n",
              "│ --- ┆ ---          ┆ --- ┆ ---   ┆   ┆ ---     ┆ --- ┆ ---       ┆ ---      │\n",
              "│ i64 ┆ i64          ┆ i64 ┆ i64   ┆   ┆ i64     ┆ i64 ┆ i64       ┆ i64      │\n",
              "╞═════╪══════════════╪═════╪═══════╪═══╪═════════╪═════╪═══════════╪══════════╡\n",
              "│ 0   ┆ 0            ┆ 0   ┆ 0     ┆ … ┆ 0       ┆ 0   ┆ 0         ┆ 1        │\n",
              "│ 1   ┆ 0            ┆ 0   ┆ 0     ┆ … ┆ 0       ┆ 0   ┆ 1         ┆ 1        │\n",
              "│ 0   ┆ 1            ┆ 1   ┆ 1     ┆ … ┆ 0       ┆ 0   ┆ 0         ┆ 0        │\n",
              "│ 0   ┆ 0            ┆ 0   ┆ 0     ┆ … ┆ 1       ┆ 0   ┆ 0         ┆ 0        │\n",
              "│ 0   ┆ 0            ┆ 0   ┆ 0     ┆ … ┆ 1       ┆ 1   ┆ 0         ┆ 0        │\n",
              "└─────┴──────────────┴─────┴───────┴───┴─────────┴─────┴───────────┴──────────┘"
            ],
            "text/html": [
              "<div><style>\n",
              ".dataframe > thead > tr,\n",
              ".dataframe > tbody > tr {\n",
              "  text-align: right;\n",
              "  white-space: pre-wrap;\n",
              "}\n",
              "</style>\n",
              "<small>shape: (5, 24)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>in</th><th>intelligence</th><th>i</th><th>about</th><th>natural</th><th>of</th><th>artificial</th><th>models</th><th>nlp</th><th>subset</th><th>learning</th><th>deep</th><th>and</th><th>fun</th><th>is</th><th>are</th><th>processing</th><th>related</th><th>closely</th><th>enjoy</th><th>machine</th><th>a</th><th>important</th><th>language</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td></tr><tr><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td></tr><tr><td>0</td><td>1</td><td>1</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>1</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>2</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td><td>0</td><td>0</td></tr></tbody></table></div>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using a sparse representation\n",
        "\n",
        "Did you notice the abundance of zeros in the count dictionaries?  We can clean up the output by only tracking things that are not zero."
      ],
      "metadata": {
        "id": "4QqjsR2qouGO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 3 - Create a vector of word counts *for each document* [Sparse representation].\n",
        "\n",
        "The *sparse representation* will only include a count for the words that appear in the given document."
      ],
      "metadata": {
        "id": "MSZG9jochruC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# deleted 0 -- sparse representaion\n",
        "# include 0 -- dense representation\n",
        "\n",
        "init_counts = {}\n",
        "update_counts = lambda cnts, w: cnts | {w:cnts[w] + 1 if w in cnts else 1} # merge left and right |\n",
        "\n",
        "(bag_of_words :=\n",
        " words\n",
        " >> map(fold(update_counts, init_counts))\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuQdkNJ2i4C1",
        "outputId": "e7924702-5209-40f8-f95b-359e09cfd471"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'natural': 1, 'language': 1, 'processing': 1, 'is': 1, 'fun': 1},\n",
              " {'language': 1, 'models': 1, 'are': 1, 'important': 1, 'in': 1, 'nlp': 1},\n",
              " {'i': 1,\n",
              "  'enjoy': 1,\n",
              "  'learning': 1,\n",
              "  'about': 1,\n",
              "  'artificial': 1,\n",
              "  'intelligence': 1},\n",
              " {'machine': 1,\n",
              "  'learning': 1,\n",
              "  'and': 1,\n",
              "  'nlp': 1,\n",
              "  'are': 1,\n",
              "  'closely': 1,\n",
              "  'related': 1},\n",
              " {'deep': 1,\n",
              "  'learning': 2,\n",
              "  'is': 1,\n",
              "  'a': 1,\n",
              "  'subset': 1,\n",
              "  'of': 1,\n",
              "  'machine': 1}]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Let's redo that, but remove the stop words."
      ],
      "metadata": {
        "id": "XWbkxBPZfhQA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "eng_stop_words = set(stopwords.words('english'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6r-M7XsflDO",
        "outputId": "60637a5d-948f-4ce4-c9ab-e0ea2169b5ed"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(words :=\n",
        " documents\n",
        " >> map(obj.lower())\n",
        " >> map(obj.split(' '))\n",
        " >> map(filter(lambda w: w not in eng_stop_words)) # remove stop words\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqQxcHKyfoIE",
        "outputId": "c8f4f4e6-73a1-4cbf-aed0-049eeb84c071"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['natural', 'language', 'processing', 'fun'],\n",
              " ['language', 'models', 'important', 'nlp'],\n",
              " ['enjoy', 'learning', 'artificial', 'intelligence'],\n",
              " ['machine', 'learning', 'nlp', 'closely', 'related'],\n",
              " ['deep', 'learning', 'subset', 'machine', 'learning']]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(vocab :=\n",
        " words\n",
        " >> fold(lambda voc, ws: voc.union(ws), set([]))\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "036xDXyVgDUf",
        "outputId": "e9f14caf-2643-4f0c-b107-902d798789d7"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'artificial',\n",
              " 'closely',\n",
              " 'deep',\n",
              " 'enjoy',\n",
              " 'fun',\n",
              " 'important',\n",
              " 'intelligence',\n",
              " 'language',\n",
              " 'learning',\n",
              " 'machine',\n",
              " 'models',\n",
              " 'natural',\n",
              " 'nlp',\n",
              " 'processing',\n",
              " 'related',\n",
              " 'subset'}"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "init_counts = {w:0 for w in vocab}\n",
        "update_counts = lambda cnts, w: cnts | {w:cnts[w] + 1}\n",
        "\n",
        "(bag_of_words :=\n",
        " words\n",
        " >> map(fold(update_counts, init_counts))\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPfLFZB2gMRJ",
        "outputId": "49656c6d-81d8-41b8-ce48-d7274f053232"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'important': 0,\n",
              "  'learning': 0,\n",
              "  'deep': 0,\n",
              "  'fun': 1,\n",
              "  'intelligence': 0,\n",
              "  'natural': 1,\n",
              "  'machine': 0,\n",
              "  'processing': 1,\n",
              "  'related': 0,\n",
              "  'closely': 0,\n",
              "  'subset': 0,\n",
              "  'enjoy': 0,\n",
              "  'artificial': 0,\n",
              "  'models': 0,\n",
              "  'nlp': 0,\n",
              "  'language': 1},\n",
              " {'important': 1,\n",
              "  'learning': 0,\n",
              "  'deep': 0,\n",
              "  'fun': 0,\n",
              "  'intelligence': 0,\n",
              "  'natural': 0,\n",
              "  'machine': 0,\n",
              "  'processing': 0,\n",
              "  'related': 0,\n",
              "  'closely': 0,\n",
              "  'subset': 0,\n",
              "  'enjoy': 0,\n",
              "  'artificial': 0,\n",
              "  'models': 1,\n",
              "  'nlp': 1,\n",
              "  'language': 1},\n",
              " {'important': 0,\n",
              "  'learning': 1,\n",
              "  'deep': 0,\n",
              "  'fun': 0,\n",
              "  'intelligence': 1,\n",
              "  'natural': 0,\n",
              "  'machine': 0,\n",
              "  'processing': 0,\n",
              "  'related': 0,\n",
              "  'closely': 0,\n",
              "  'subset': 0,\n",
              "  'enjoy': 1,\n",
              "  'artificial': 1,\n",
              "  'models': 0,\n",
              "  'nlp': 0,\n",
              "  'language': 0},\n",
              " {'important': 0,\n",
              "  'learning': 1,\n",
              "  'deep': 0,\n",
              "  'fun': 0,\n",
              "  'intelligence': 0,\n",
              "  'natural': 0,\n",
              "  'machine': 1,\n",
              "  'processing': 0,\n",
              "  'related': 1,\n",
              "  'closely': 1,\n",
              "  'subset': 0,\n",
              "  'enjoy': 0,\n",
              "  'artificial': 0,\n",
              "  'models': 0,\n",
              "  'nlp': 1,\n",
              "  'language': 0},\n",
              " {'important': 0,\n",
              "  'learning': 2,\n",
              "  'deep': 1,\n",
              "  'fun': 0,\n",
              "  'intelligence': 0,\n",
              "  'natural': 0,\n",
              "  'machine': 1,\n",
              "  'processing': 0,\n",
              "  'related': 0,\n",
              "  'closely': 0,\n",
              "  'subset': 1,\n",
              "  'enjoy': 0,\n",
              "  'artificial': 0,\n",
              "  'models': 0,\n",
              "  'nlp': 0,\n",
              "  'language': 0}]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using `CountVectorizer` to get the bag of words"
      ],
      "metadata": {
        "id": "M72cYIUhew5w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer() # this is the instance of CountVectorizer(object)\n",
        "\n",
        "(X := vectorizer.fit_transform(documents))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-l0m0pHeinK",
        "outputId": "4dc6c0dd-4c11-4f65-9dd9-01fe6665a8d7"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<5x22 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 29 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChAxLaCnfHRj",
        "outputId": "c5970347-b4aa-4821-a60b-316d4ee140eb"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 16)\t1\n",
            "  (0, 12)\t1\n",
            "  (0, 19)\t1\n",
            "  (0, 11)\t1\n",
            "  (0, 7)\t1\n",
            "  (1, 12)\t1\n",
            "  (1, 15)\t1\n",
            "  (1, 2)\t1\n",
            "  (1, 8)\t1\n",
            "  (1, 9)\t1\n",
            "  (1, 17)\t1\n",
            "  (2, 6)\t1\n",
            "  (2, 13)\t1\n",
            "  (2, 0)\t1\n",
            "  (2, 3)\t1\n",
            "  (2, 10)\t1\n",
            "  (3, 2)\t1\n",
            "  (3, 17)\t1\n",
            "  (3, 13)\t1\n",
            "  (3, 14)\t1\n",
            "  (3, 1)\t1\n",
            "  (3, 4)\t1\n",
            "  (3, 20)\t1\n",
            "  (4, 11)\t1\n",
            "  (4, 13)\t2\n",
            "  (4, 14)\t1\n",
            "  (4, 5)\t1\n",
            "  (4, 21)\t1\n",
            "  (4, 18)\t1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Exercise 3.3.2**\n",
        "\n",
        "Explain the previous output."
      ],
      "metadata": {
        "id": "UJeiJh3U306I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<font color = red>\n",
        "CountVectorizer form sklearn counts the number of the targer vocabularies. The number on the left in the () indicates the row# and the number on the right in the () indicates the columns. This is the sparse representation because there is no 0 counts. (0, 16) -- 1 means that the document 0 has the vocabulary #16 once.**"
      ],
      "metadata": {
        "id": "RSXBbSby38-I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example - Text Classification with Bag of Words\n",
        "\n",
        "Let's use Naive Bayes classifier to classify our documents using the Bag of Words features.\n",
        "\n",
        "**Note.** While this toy example is too small of be of real interest, most real problems will involve very similar code."
      ],
      "metadata": {
        "id": "CTUE8JmHk28G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "# Cases\n",
        "(documents :=\n",
        " [\"Natural language processing is fun\",\n",
        "  \"Language models are important in NLP\",\n",
        "  \"I enjoy learning about artificial intelligence\",\n",
        "  \"Machine learning and NLP are closely related\",\n",
        "  \"Deep learning is a subset of machine learning\",\n",
        " ]\n",
        ")\n",
        "\n",
        "# Target vector - 1 ==> NLP-related, 0 for AI related\n",
        "labels = [1, 1, 0, 1, 0]\n",
        "\n",
        "# Create the sparse feature set\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "X = vectorizer.fit_transform(documents)\n",
        "\n",
        "# Create a training and test (validation) set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, labels,\n",
        "                                                    test_size = 0.2,\n",
        "                                                    random_state=42)\n",
        "\n",
        "# Train the model\n",
        "classifier = MultinomialNB()\n",
        "\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "(accuracy := accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9k5dKr4afRKl",
        "outputId": "bb4883bb-8e68-4d61-e8cb-27179e8b53c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJVRH36Ll4g3",
        "outputId": "3eff37be-3d32-447e-955b-ba06b9bf53bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 11)\t1\n",
            "  (0, 13)\t2\n",
            "  (0, 14)\t1\n",
            "  (0, 5)\t1\n",
            "  (0, 21)\t1\n",
            "  (0, 18)\t1\n",
            "  (1, 6)\t1\n",
            "  (1, 13)\t1\n",
            "  (1, 0)\t1\n",
            "  (1, 3)\t1\n",
            "  (1, 10)\t1\n",
            "  (2, 16)\t1\n",
            "  (2, 12)\t1\n",
            "  (2, 19)\t1\n",
            "  (2, 11)\t1\n",
            "  (2, 7)\t1\n",
            "  (3, 2)\t1\n",
            "  (3, 17)\t1\n",
            "  (3, 13)\t1\n",
            "  (3, 14)\t1\n",
            "  (3, 1)\t1\n",
            "  (3, 4)\t1\n",
            "  (3, 20)\t1 [0, 0, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PnXtj-ccmt5-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}